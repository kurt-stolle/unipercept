{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensordict experiments\n",
    "\n",
    "The current documentation of the `tensordict` library can be unclear at points. This notebook experimentally validates \n",
    "or disproves some ambiguities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are `tensorclass` objects preserved as an instance when they are part of a `TensorDict`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        tc: TestClass(\n",
      "            a=Tensor(shape=torch.Size([3, 6, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "            b=Tensor(shape=torch.Size([3, 1, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "            batch_size=torch.Size([3]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        value: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([3]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p>Type is <strong>preserved</strong></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from tensordict import TensorDict, tensorclass\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "@tensorclass\n",
    "class TestClass:\n",
    "    a: torch.Tensor\n",
    "    b: torch.Tensor\n",
    "\n",
    "\n",
    "tc = TestClass(a=torch.randn(3, 6, 4), b=torch.randn(3, 1, 2), batch_size=[3])\n",
    "tc_key = \"tc\"\n",
    "td = TensorDict(\n",
    "    {\n",
    "        \"value\": torch.randn(3, 3),\n",
    "        tc_key: tc,\n",
    "    },\n",
    "    batch_size=[3],\n",
    ")\n",
    "\n",
    "print(td)\n",
    "\n",
    "if type(td[tc_key]) is TestClass:\n",
    "    display(HTML(f\"<p>Type is <strong>preserved</strong></p>\"))\n",
    "else:\n",
    "    display(HTML(f\"<p>Type is <strong>not preserved</strong></p>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can ``Tensorclass`` objects be iterated over and set?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1]) tensor([[-1.8834],\n",
      "        [ 0.2882],\n",
      "        [-0.5761]])\n",
      "torch.Size([3, 1]) tensor([[-0.7000],\n",
      "        [ 1.6227],\n",
      "        [-0.3501]])\n",
      "0\n",
      "1\n",
      "2\n",
      "torch.Size([3, 1]) tensor([[-0.0000],\n",
      "        [ 0.2882],\n",
      "        [-1.1522]])\n",
      "torch.Size([3, 1]) tensor([[-0.7000],\n",
      "        [ 2.6227],\n",
      "        [ 1.6499]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unipercept.utils.tensorclass import Tensorclass\n",
    "\n",
    "\n",
    "class TestClass(Tensorclass):\n",
    "    a: torch.Tensor\n",
    "    b: torch.Tensor\n",
    "\n",
    "\n",
    "tc = TestClass(a=torch.randn(3, 1), b=torch.randn(3, 1), batch_size=[3])\n",
    "\n",
    "print(tc.a.shape, tc.a)\n",
    "print(tc.b.shape, tc.b)\n",
    "\n",
    "for batch_idx, tc_item in enumerate(tc):\n",
    "    print(batch_idx)\n",
    "    tc_item = tc_item.clone()\n",
    "    tc_item.a *= batch_idx\n",
    "    tc_item.b += batch_idx\n",
    "\n",
    "    tc[batch_idx] = tc_item\n",
    "\n",
    "\n",
    "print(tc.a.shape, tc.a)\n",
    "print(tc.b.shape, tc.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the flat PyTree Spec look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        b: Tensor(shape=torch.Size([3, 5]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        c: TensorDict(\n",
      "            fields={\n",
      "                d: Tensor(shape=torch.Size([3, 5, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                e: Tensor(shape=torch.Size([3, 5, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                f: TensorDict(\n",
      "                    fields={\n",
      "                        g: Tensor(shape=torch.Size([3, 5, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        h: Image(shape=torch.Size([3, 5, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([3, 5, 3]),\n",
      "                    device=None,\n",
      "                    is_shared=False)},\n",
      "            batch_size=torch.Size([3, 5]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        x: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "PyTree: \n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'unipercept.data.points._image.Image'>\n",
      "<class 'torch.Tensor'>\n",
      "Structure: {'keys': ['a', 'b', 'c', 'x'], 'batch_size': torch.Size([]), 'names': []}\n",
      "*\n",
      "*\n",
      "TreeSpec(TensorDict, {'keys': ['d', 'e', 'f'], 'batch_size': torch.Size([3, 5]), 'names': [None, None]}, [*,\n",
      "                                                                                                          *,\n",
      "                                                                                                          TreeSpec(TensorDict, {'keys': ['g', 'h'], 'batch_size': torch.Size([3, 5, 3]), 'names': [None, None, None]}, [*,\n",
      "                                                                                                                                                                                                                        *])])\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "from tensordict import TensorDict\n",
    "from torch.utils._pytree import tree_flatten\n",
    "import torch\n",
    "from unipercept.data.points import Image\n",
    "\n",
    "td = TensorDict.from_dict(\n",
    "    {\n",
    "        \"a\": torch.randn(3, 1),\n",
    "        \"b\": torch.randn(3, 5),\n",
    "        \"c\": TensorDict.from_dict(\n",
    "            {\n",
    "                \"d\": torch.randn(3, 5, 1),\n",
    "                \"e\": torch.randn(3, 5, 6),\n",
    "                \"f\": TensorDict.from_dict(\n",
    "                    {\n",
    "                        \"g\": torch.randn(3, 5, 3),\n",
    "                        \"h\": torch.randn(3, 5, 3, 2).as_subclass(Image),\n",
    "                    }\n",
    "                ),\n",
    "            }\n",
    "        ),\n",
    "        \"x\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(td)\n",
    "\n",
    "td_flat, td_structure = tree_flatten(td)\n",
    "\n",
    "print(f\"PyTree: \\n\" + \"\\n\".join([str(type(x)) for x in td_flat]))\n",
    "print(\n",
    "    f\"Structure: {td_structure.context}\\n\"\n",
    "    + \"\\n\".join([str(x) for x in td_structure.children_specs])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unipercept311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
